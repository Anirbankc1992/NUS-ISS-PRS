{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRNVzhoo1clG"
   },
   "source": [
    "## **1. Mount google drive**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dOQ-2xS_MYHi"
   },
   "source": [
    "## **2. Import the necessary libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoi4gWDELtek"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\anaconda\\envs\\anirban\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow:  1.14.0\n",
      "numpy:       1.18.5\n",
      "matplotlib:  2.2.5\n",
      "sklearn:     0.23.1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow: \", tf.__version__)\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0amhwjZ4M2m-"
   },
   "source": [
    "## **3.Create a function to plot image without axis**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OFxsBB1mNXl2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function implt at 0x00000249A7002288>\n"
     ]
    }
   ],
   "source": [
    "def implt(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(implt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3N41iixORPz"
   },
   "source": [
    "## **4. Set matplotlib to have seaborn plot style**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyO5OsUrOYNQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib setup completes.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5w2jAiKZOmgP"
   },
   "source": [
    "## **5. Prepare Cifar10 data for training and testing**\n",
    "---\n",
    "* Step 1: Load the cifar10 \n",
    "* Step 2: Check the shape and type of the data\n",
    "* Step 3: Convert the data into float32 and rescale the values from the range of 0\\~255 into 0\\~1\n",
    "* Step 4: Retrieve the row size and the column size of each image\n",
    "* Step 5: Perform one-hot enconding on the labels\n",
    "* Step 6: Retrieve the number of classes in this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3Ad2V0pO1TX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trDat is (50000, 32, 32, 3) and the type of trDat is uint8\n",
      "The shape of tsDat is (10000, 32, 32, 3) and the type of tsDat is uint8\n",
      "\n",
      "The shape of trLbl is (50000, 1) and the type of trLbl is uint8\n",
      "The shape of tsLbl is (10000, 1) and the type of tsLbl is int32\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "data            = cifar10.load_data()\n",
    "(trDat, trLbl)  = data[0]\n",
    "(tsDat, tsLbl)  = data[1]\n",
    "\n",
    "                                                                                # Step 2\n",
    "print(\"The shape of trDat is\", trDat.shape, \"and the type of trDat is\", trDat.dtype)\n",
    "print(\"The shape of tsDat is\", tsDat.shape, \"and the type of tsDat is\", tsDat.dtype)\n",
    "print(\"\")\n",
    "print(\"The shape of trLbl is\", trLbl.shape, \"and the type of trLbl is\", trLbl.dtype)\n",
    "print(\"The shape of tsLbl is\", tsLbl.shape, \"and the type of tsLbl is\", tsLbl.dtype)\n",
    "\n",
    "                                                                                # Step 3\n",
    "trDat           = trDat.astype('float32')/255\n",
    "tsDat           = tsDat.astype('float32')/255\n",
    "\n",
    "                                                                                # Step 4\n",
    "imgrows         = trDat.shape[1]\n",
    "imgclms         = trDat.shape[2]\n",
    "channel         = trDat.shape[3]\n",
    "\n",
    "                                                                                # Step 5\n",
    "trLbl           = to_categorical(trLbl)\n",
    "tsLbl           = to_categorical(tsLbl)\n",
    "                               \n",
    "num_classes     = tsLbl.shape[1]                                                # Step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DoP3WcoJW-jZ"
   },
   "source": [
    "## **6. Define the resnet model (to be completed)**\n",
    "___\n",
    "* Step 1: Setup the optimizer to be used for training\n",
    "* Step 2: Set a name for the coming model (required for saving)\n",
    "* Step 3: Function to create layers for the resnet\n",
    "* Step 4: Function to create residual blocks\n",
    "* Step 5: Define the resnet model (to be completed)\n",
    "* Step 6: Create models for training and testing\n",
    "* Step 7: Display the summary of the model of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HMOes0kXCPd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-df00658276d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                                                                                 \u001b[1;31m# Step 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m \u001b[0mmodel\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mcreateResNetV1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# This is meant for training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[0mmodelGo\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mcreateResNetV1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# This is used for final testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-df00658276d0>\u001b[0m in \u001b[0;36mcreateResNetV1\u001b[1;34m(inputShape, numClasses)\u001b[0m\n\u001b[0;32m     86\u001b[0m                    numClasses=10):\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                                                                                 \u001b[1;31m# Step 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optmz       = optimizers.Adam(lr=0.001)                                         # Step 1\n",
    "modelname   = 'cifar10ResV1Cfg5'                                                # Step 2\n",
    "\n",
    "                                                                                # Step 3\n",
    "def resLyr(inputs,\n",
    "           numFilters=16,\n",
    "           kernelSz=3,\n",
    "           strides=1,\n",
    "           activation='relu',\n",
    "           batchNorm=True,\n",
    "           convFirst=True,\n",
    "           lyrName=None):\n",
    "\n",
    "    convLyr     = Conv2D(numFilters,\n",
    "                         kernel_size=kernelSz,\n",
    "                         strides=strides,\n",
    "                         padding='same',\n",
    "                         kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=l2(1e-4),\n",
    "                         name=lyrName+'_conv' if lyrName else None)\n",
    "    x           = inputs\n",
    "    \n",
    "    if convFirst:\n",
    "        x       = convLyr(x)\n",
    "        \n",
    "        if batchNorm:\n",
    "            x   = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
    "            \n",
    "        if activation is not None:\n",
    "            x   = Activation(activation,\n",
    "                             name=lyrName+'_'+activation if lyrName else None)(x)\n",
    "    else:\n",
    "        if batchNorm:\n",
    "            x   = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
    "            \n",
    "        if activation is not None:\n",
    "            x   = Activation(activation,\n",
    "                             name=lyrName+'_'+activation if lyrName else None)(x)\n",
    "            \n",
    "        x       = convLyr(x)\n",
    "    return x\n",
    "\n",
    "                                                                                # Step 4\n",
    "def resBlkV1(inputs,\n",
    "             numFilters=16,\n",
    "             numBlocks=3,\n",
    "             downsampleOnFirst=True,\n",
    "             names=None):\n",
    "    \n",
    "    x       = inputs\n",
    "    \n",
    "    for run in range(0,numBlocks):\n",
    "        strides = 1\n",
    "        blkStr  = str(run+1)\n",
    "        \n",
    "        if downsampleOnFirst and run == 0:\n",
    "            strides     = 2\n",
    "            \n",
    "        y       = resLyr(inputs=x,\n",
    "                         numFilters=numFilters,\n",
    "                         strides=strides,\n",
    "                         lyrName=names+'_Blk'+blkStr+'_Res1' if names else None)\n",
    "        y       = resLyr(inputs=y,\n",
    "                         numFilters=numFilters,\n",
    "                         activation=None,\n",
    "                         lyrName=names+'_Blk'+blkStr+'_Res2' if names else None)\n",
    "        \n",
    "        if downsampleOnFirst and run == 0:\n",
    "            x   = resLyr(inputs=x,\n",
    "                         numFilters=numFilters,\n",
    "                         kernelSz=1,\n",
    "                         strides=strides,\n",
    "                         activation=None,\n",
    "                         batchNorm=False,\n",
    "                         lyrName=names+'_Blk'+blkStr+'_lin' if names else None)\n",
    "\n",
    "        x       = add([x,y],\n",
    "                      name=names+'_Blk'+blkStr+'_add' if names else None)\n",
    "        x       = Activation('relu',\n",
    "                             name=names+'_Blk'+blkStr+'_relu' if names else None)(x)\n",
    "        \n",
    "    return x\n",
    "    \n",
    "                                                                                # Step 5\n",
    "def createResNetV1(inputShape=(32,32,3),\n",
    "                   numClasses=10):\n",
    "\n",
    "    return model\n",
    "\n",
    "                                                                                # Step 6\n",
    "model       = createResNetV1()  # This is meant for training\n",
    "modelGo     = createResNetV1()  # This is used for final testing\n",
    "\n",
    "model.summary()                                                                 # Step 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlquJEaFZxV9"
   },
   "source": [
    "## **7. Create the callbacks to be applied during training**\n",
    "---\n",
    "* Step 1: Create a callback to save the model from an epoch when validation accuracy is the highest\n",
    "* Step 2: Create a callback to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
    "* Step 3: Put the two callback objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-a1LSCbahKy"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "def lrSchedule(epoch):\n",
    "    lr  = 1e-3\n",
    "    \n",
    "    if epoch > 160:\n",
    "        lr  *= 0.5e-3        \n",
    "    elif epoch > 140:\n",
    "        lr  *= 1e-3       \n",
    "    elif epoch > 120:\n",
    "        lr  *= 1e-2     \n",
    "    elif epoch > 80:\n",
    "        lr  *= 1e-1\n",
    "        \n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "LRScheduler     = LearningRateScheduler(lrSchedule)\n",
    "\n",
    "                                                                                # Step 2\n",
    "folderpath      = '/content/gdrive/My Drive/iss/prumls/colab/'\n",
    "filepath        = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')                       # Step 2\n",
    "callbacks_list  = [checkpoint,csv_logger,LRScheduler]                           # Step 3\n",
    "\n",
    "print(\"Callbacks created:\")\n",
    "print(callbacks_list[0])\n",
    "print(callbacks_list[1])\n",
    "print(callbacks_list[2])\n",
    "print('')\n",
    "print(\"Path to model:\", filepath)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1mKgjQsmfOBz"
   },
   "source": [
    "## **8. Train the deep learning model with image augmentation (to be completed)**\n",
    "___\n",
    "* Step 1: Create the image data generator (for image augmentation)\n",
    "* Step 2: Train the model with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23lUNwpGfV0A"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "\n",
    "\n",
    "\n",
    "                                                                                # Step 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TevfJTd-s0nk"
   },
   "source": [
    "## **9. Validate the deep learning model**\n",
    "---\n",
    "* Step 1: Load the trained weights and compile the model\n",
    "* Step 2: Make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2sVtWmcVtiV5"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "modelGo.load_weights(filepath)\n",
    "modelGo.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optmz, \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "predicts    = modelGo.predict(tsDat)                                            # Step 2\n",
    "print(\"Prediction completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aOCUljp5qq4"
   },
   "source": [
    "## **10. Report classification metrics**\n",
    "---\n",
    "* Step 1: Setup the label\n",
    "* Step 2: Convert label from one-hot to integer\n",
    "* Step 3: Calculate the accuracy score\n",
    "* Step 4: Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tI4hBmk5uRh"
   },
   "outputs": [],
   "source": [
    "                                                                                # Step 1\n",
    "labelname   = ['airplane',          # The label for reporting metrics\n",
    "               'automobile',\n",
    "               'bird',\n",
    "               'cat',\n",
    "               'deer',\n",
    "               'dog',\n",
    "               'frog',\n",
    "               'horse',\n",
    "               'ship',\n",
    "               'truck']\n",
    "                                                                                # Step 2\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(tsLbl,axis=1)\n",
    "\n",
    "testScores  = metrics.accuracy_score(testout,predout)                           # Step 3\n",
    "\n",
    "                                                                                # Step 4\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=labelname,\n",
    "                                    digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gEK_4UXN6IVa"
   },
   "source": [
    "## **11. Print confusion matrix**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCBJCYp26L1t"
   },
   "outputs": [],
   "source": [
    "confusion   = metrics.confusion_matrix(testout,predout)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QMIDPD46UGT"
   },
   "source": [
    "## **12. Plot curves on validation loss and accuracy**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qr2ZbvUi6YHf"
   },
   "outputs": [],
   "source": [
    "records     = pd.read_csv(folderpath+modelname +'.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.50,1.00,1.50])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_accuracy'],label=\"validation\")\n",
    "plt.plot(records['accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWoTz-bLug3X"
   },
   "source": [
    "## **13. Save the model plot**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tz1YfuV1ujcE"
   },
   "outputs": [],
   "source": [
    "plotpath  = folderpath+modelname+'_plot.png'\n",
    "plot_model(model, \n",
    "           to_file=plotpath, \n",
    "           show_shapes=True, \n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')\n",
    "\n",
    "print(\"Path to plot:\", plotpath)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "prumls-wks4-1-<yourname>.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
